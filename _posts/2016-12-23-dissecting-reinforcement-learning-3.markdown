---
layout: post
title:  "Dissecting Reinforcement Learning-Part.2"
date:   2016-12-23 19:00:00 +0000
description: Explaining the basic ideas behind reinforcement learning. In particular, Markov Decision Process, Bellman equation, Value iteration and Policy Iteration algorithms, policy iteration through linear algebra methods. It includes full working code written in Python.
author: Massimiliano Patacchiola
comments: false
published: false
---

[MC problem and possible ways to solve them with TD][6.2 pag. 138]
[Bootstrapping]
[What TD Learning is]
[TD(0) the simplest form of TD learning]
[TD(lamda) Eligibility traces]
[TD generally converge faster the MC on stochastic task][Example 6.2 pag. 139]
[Batch Learning]
[SARSA (on-policy) TD control]
[On-Policy and Off-Policy]
[for "off-policy example" cite Deep Reinforcement Learning for Robotic Manipulation with Asynchronous Off-Policy Updates]
[Q-Learning]


[Value Function Approximation]
[Action-Value Function Approximation]
[Linear Approximation]
[Neural Network Approximation]
[Example in python with tensorflow]
[Policy Gradient][Lesson 7 of David Silver's course][See pong from pixels post]
[Policy Optimization without gradient (e.g. genetic algoritm which are actor only model)]

[Deep Reinforcement Learning]
[Playing Atari with Deep Reinforcement Learning - 2013]
[Human-level control through deep reinforcement learning - 2015]
[Replay Memory]
[Improving Replay Memory with Prioritized Sweeping][9.4, pag 238; cit in "Human level control through deep RL" in section "Training algorithm for deep Q-networks"]
[Example in Python, cleaning robot 3D]

[Actor-Critic]
[Mastering the game of Go with deep neural networks and tree search - 2016]


Conclusions
-----------



Resources
----------

The [dissecting-reinforcement-learning](https://github.com/mpatacchiola/dissecting-reinforcement-learning) repository.

The [setosa blog](http://setosa.io/) containing a good-looking simulator for Markov chains.

Official [github repository](https://github.com/aimacode) for the book *"Artificial Intelligence: a Modern Approach"*.

References
------------

Bellman, R. (1957). A Markovian decision process (No. P-1066). RAND CORP SANTA MONICA CA.

Russell, S. J., Norvig, P., Canny, J. F., Malik, J. M., & Edwards, D. D. (2003). Artificial intelligence: a modern approach (Vol. 2). Upper Saddle River: Prentice hall.



